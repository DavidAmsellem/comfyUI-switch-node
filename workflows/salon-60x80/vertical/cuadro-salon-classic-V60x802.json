{
  "1": {
    "inputs": {
      "text": "rustic minimalist architectural living room interior front view, exposed natural materials like raw wood beams and stone walls, smooth neutral plaster surfaces, polished concrete or light oak flooring, large open space with high ceilings, floor-to-ceiling windows with natural light, custom-built wooden furniture with clean lines, earthy color palette (beige, clay, taupe), linen or wool textures, single sculptural armchair or bench, minimal decor with artisanal touches (ceramic vase, woven basket), soft shadows, serene atmosphere, balanced proportions, frontal perspective, high quality, photorealistic",
      "clip": [
        "4",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "2": {
    "inputs": {
      "width": 512,
      "height": 512,
      "batch_size": 1
    },
    "class_type": "EmptyLatentImage",
    "_meta": {
      "title": "Empty Latent Image"
    }
  },
  "4": {
    "inputs": {
      "ckpt_name": "Deliberate_v2.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "7": {
    "inputs": {
      "samples": [
        "175",
        0
      ],
      "vae": [
        "4",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "9": {
    "inputs": {
      "text": "angled view, cluttered decor, bright colors, modern plastics, wall art, framed pictures, metal furniture, glossy finishes, wall-mounted TVs, vibrant patterns, heavy curtains, neon lighting, excessive ornamentation, dark lighting, low quality, blurry",
      "clip": [
        "4",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "65": {
    "inputs": {
      "method": "average",
      "embed1": [
        "112",
        0
      ]
    },
    "class_type": "IPAdapterCombineEmbeds",
    "_meta": {
      "title": "IPAdapter Combine Embeds"
    }
  },
  "78": {
    "inputs": {
      "weight": 1.0000000000000002,
      "weight_type": "linear",
      "start_at": 0,
      "end_at": 1,
      "embeds_scaling": "V only",
      "model": [
        "79",
        0
      ],
      "ipadapter": [
        "80",
        0
      ],
      "pos_embed": [
        "65",
        0
      ],
      "clip_vision": [
        "81",
        0
      ]
    },
    "class_type": "IPAdapterEmbeds",
    "_meta": {
      "title": "IPAdapter Embeds"
    }
  },
  "79": {
    "inputs": {
      "preset": "PLUS (high strength)",
      "model": [
        "4",
        0
      ]
    },
    "class_type": "IPAdapterUnifiedLoader",
    "_meta": {
      "title": "IPAdapter Unified Loader"
    }
  },
  "80": {
    "inputs": {
      "ipadapter_file": "ip-adapter-plus_sd15.safetensors"
    },
    "class_type": "IPAdapterModelLoader",
    "_meta": {
      "title": "IPAdapter Model Loader"
    }
  },
  "81": {
    "inputs": {
      "clip_name": "CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors"
    },
    "class_type": "CLIPVisionLoader",
    "_meta": {
      "title": "Load CLIP Vision"
    }
  },
  "97": {
    "inputs": {
      "image": "f14a484a35c7415cafd1622c27582bca.png"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "102": {
    "inputs": {
      "width": [
        "136",
        4
      ],
      "height": [
        "136",
        5
      ],
      "interpolation": "nearest",
      "method": "stretch",
      "condition": "always",
      "multiple_of": 0,
      "image": [
        "361",
        0
      ]
    },
    "class_type": "ImageResize+",
    "_meta": {
      "title": "ðŸ”§ Image Resize"
    }
  },
  "104": {
    "inputs": {
      "image": "imagenes_nodo_104/cuadro-salon-classic-V60x802.png"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "107": {
    "inputs": {
      "width": 512,
      "height": 512,
      "interpolation": "nearest",
      "method": "stretch",
      "condition": "always",
      "multiple_of": 0,
      "image": [
        "104",
        0
      ]
    },
    "class_type": "ImageResize+",
    "_meta": {
      "title": "ðŸ”§ Image Resize"
    }
  },
  "110": {
    "inputs": {
      "interpolation": "LANCZOS",
      "crop_position": "top",
      "sharpening": 0,
      "image": [
        "107",
        0
      ]
    },
    "class_type": "PrepImageForClipVision",
    "_meta": {
      "title": "Prep Image For ClipVision"
    }
  },
  "112": {
    "inputs": {
      "weight": 0.38000000000000006,
      "ipadapter": [
        "80",
        0
      ],
      "image": [
        "110",
        0
      ],
      "clip_vision": [
        "81",
        0
      ]
    },
    "class_type": "IPAdapterEncoder",
    "_meta": {
      "title": "IPAdapter Encoder"
    }
  },
  "115": {
    "inputs": {
      "upscale_method": "lanczos",
      "width": 1200,
      "height": 1200,
      "crop": "disabled",
      "image": [
        "7",
        0
      ]
    },
    "class_type": "ImageScale",
    "_meta": {
      "title": "Upscale Image"
    }
  },
  "136": {
    "inputs": {
      "padding": 0,
      "blur": 0,
      "mask": [
        "247",
        0
      ],
      "image_optional": [
        "244",
        0
      ]
    },
    "class_type": "MaskBoundingBox+",
    "_meta": {
      "title": "ðŸ”§ Mask Bounding Box"
    }
  },
  "142": {
    "inputs": {
      "x": [
        "136",
        2
      ],
      "y": [
        "136",
        3
      ],
      "resize_source": false,
      "destination": [
        "115",
        0
      ],
      "source": [
        "102",
        0
      ]
    },
    "class_type": "ImageCompositeMasked",
    "_meta": {
      "title": "ImageCompositeMasked"
    }
  },
  "143": {
    "inputs": {
      "images": [
        "142",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "161": {
    "inputs": {
      "ipadapter_file": "ip-adapter-plus_sd15.safetensors"
    },
    "class_type": "IPAdapterModelLoader",
    "_meta": {
      "title": "IPAdapter Model Loader"
    }
  },
  "162": {
    "inputs": {
      "clip_name": "CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors"
    },
    "class_type": "CLIPVisionLoader",
    "_meta": {
      "title": "Load CLIP Vision"
    }
  },
  "175": {
    "inputs": {
      "seed": 237390016869983,
      "steps": 30,
      "cfg": 5.3,
      "sampler_name": "dpmpp_2m",
      "scheduler": "karras",
      "denoise": 1,
      "model": [
        "78",
        0
      ],
      "positive": [
        "1",
        0
      ],
      "negative": [
        "9",
        0
      ],
      "latent_image": [
        "2",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "244": {
    "inputs": {
      "image": "60x80-high.png"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "247": {
    "inputs": {
      "method": "intensity",
      "image": [
        "244",
        0
      ]
    },
    "class_type": "Image To Mask",
    "_meta": {
      "title": "Image To Mask"
    }
  },
  "345": {
    "inputs": {
      "yolo_world_model": "yolo_world/l"
    },
    "class_type": "Yoloworld_ModelLoader_Zho",
    "_meta": {
      "title": "ðŸ”ŽYoloworld Model Loader"
    }
  },
  "346": {
    "inputs": {
      "device": "CPU"
    },
    "class_type": "ESAM_ModelLoader_Zho",
    "_meta": {
      "title": "ðŸ”ŽESAM Model Loader"
    }
  },
  "352": {
    "inputs": {
      "mask": [
        "356",
        1
      ]
    },
    "class_type": "MaskToImage",
    "_meta": {
      "title": "Convert Mask to Image"
    }
  },
  "356": {
    "inputs": {
      "categories": "window, mirror, bookcase, wall patterns, wallpaper, wall decals, wall art, wall decorations, wall graphics, wall ornaments, wall motifs, bed",
      "confidence_threshold": 0.10000000000000002,
      "iou_threshold": 0.10000000000000002,
      "box_thickness": 2,
      "text_thickness": 2,
      "text_scale": 1,
      "with_confidence": true,
      "with_class_agnostic_nms": false,
      "with_segmentation": true,
      "mask_combined": false,
      "mask_extracted": false,
      "mask_extracted_index": 0,
      "yolo_world_model": [
        "345",
        0
      ],
      "esam_model": [
        "346",
        0
      ],
      "image": [
        "7",
        0
      ]
    },
    "class_type": "Yoloworld_ESAM_Zho",
    "_meta": {
      "title": "ðŸ”ŽYoloworld ESAM"
    }
  },
  "357": {
    "inputs": {
      "images": [
        "352",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "360": {
    "inputs": {
      "images": [
        "356",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "361": {
    "inputs": {
      "preset": "charcoal",
      "frame_width": 20,
      "image": [
        "97",
        0
      ]
    },
    "class_type": "DynamicFrameNode",
    "_meta": {
      "title": "Dynamic Frame Generator"
    }
  }
}